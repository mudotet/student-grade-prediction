import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# --- Cáº¥u hÃ¬nh ---
data_path = 'C:/Users/TUS/Downloads/student_grade_prediction/backend/student-mat.csv'
model_path = 'trained_model.npz'

# --- Tiá»n xá»­ lÃ½ dá»¯ liá»‡u ---
def preprocess_data(data):
    data['internet'] = data['internet'].map({'no': 0, 'yes': 1})
    data['famsup'] = data['famsup'].map({'no': 0, 'yes': 1})
    data['schoolsup'] = data['schoolsup'].map({'no': 0, 'yes': 1})

    data = data.dropna(subset=['studytime', 'failures', 'famrel', 'health', 'internet',
                               'absences', 'famsup', 'schoolsup', 'G1', 'G2', 'G3'])

    input_features = ['studytime', 'failures', 'famrel', 'health', 'internet',
                      'absences', 'famsup', 'schoolsup', 'G1', 'G2']
    target_feature = 'G3'

    X = data[input_features].values
    y = data[target_feature].values
    return data, X, y

# --- HÃ m dá»± Ä‘oÃ¡n ---
def predict(X, w, b):
    return np.dot(X, w) + b

# --- TÃ­nh MSE ---
def mean_squared_error_manual(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

# --- Váº½ biá»ƒu Ä‘á»“ ---
def visualize(data, X, y, w, b, cost_history):
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    y_pred = np.array([predict(x, w, b) for x in X_test])
    y_pred = np.clip(y_pred, 0, 20)
    mse = mean_squared_error_manual(y_test, y_pred)

    # --- 1. Váº½ biá»ƒu Ä‘á»“ tá»«ng thuá»™c tÃ­nh Ä‘áº§u vÃ o vá»›i G3 ---
    input_features = ['G1', 'G2']
    
    for feature in input_features:
        plt.figure(figsize=(6, 4))
        sns.regplot(x=data[feature], y=data['G3'], ci=None, scatter_kws={'alpha': 0.6})
        plt.title(f"{feature} vs G3 (kÃ¨m Ä‘Æ°á»ng há»“i quy)")
        plt.xlabel(feature)
        plt.ylabel("G3")
        plt.grid(True)
        plt.tight_layout()
        plt.show()

    # --- 2. Äá»“ thá»‹ chi phÃ­ ---
    plt.figure(figsize=(8, 5))
    plt.plot(range(len(cost_history)), cost_history, color='blue')
    plt.title("ğŸ“‰ Äá»“ thá»‹ Chi phÃ­ theo sá»‘ láº§n láº·p")
    plt.xlabel("Iterations")
    plt.ylabel("Cost")
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # --- 3. So sÃ¡nh G3 thá»±c táº¿ vs G3 dá»± Ä‘oÃ¡n ---
    plt.figure(figsize=(8, 5))
    plt.scatter(y_test, y_pred, alpha=0.7, color='green')
    plt.plot([0, 20], [0, 20], 'r--')
    plt.title(f"G3 Thá»±c táº¿ vs Dá»± Ä‘oÃ¡n (MSE = {mse:.2f})")
    plt.xlabel("G3 Thá»±c táº¿")
    plt.ylabel("G3 Dá»± Ä‘oÃ¡n")
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    y_pred = np.array([predict(x, w, b) for x in X_test])
    y_pred = np.clip(y_pred, 0, 20)
    mse = mean_squared_error_manual(y_test, y_pred)

    # 1. Ma tráº­n tÆ°Æ¡ng quan
    plt.figure(figsize=(12, 8))
    sns.heatmap(data.select_dtypes(include=[np.number]).corr(), annot=True, cmap='coolwarm', fmt=".2f")

    plt.title("ğŸ“Š Ma tráº­n tÆ°Æ¡ng quan giá»¯a cÃ¡c thuá»™c tÃ­nh")
    plt.tight_layout()
    plt.show()

# --- Main ---
def main():
    # Äá»c dá»¯ liá»‡u
    raw_data = pd.read_csv(data_path)
    data, X, y = preprocess_data(raw_data)

    # Load mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    model = np.load(model_path)
    w = model['w']
    b = model['b']
    cost_history = model['cost_history']

    # Hiá»ƒn thá»‹
    visualize(data, X, y, w, b, cost_history)

# --- Cháº¡y chÆ°Æ¡ng trÃ¬nh ---
if __name__ == '__main__':
    main()
